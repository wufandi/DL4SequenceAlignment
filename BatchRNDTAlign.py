import torch
import tqdm
import os
import pickle
import sys
import argparse
import time
import datetime
import shutil
from torch.utils import data
from torch.multiprocessing import Pool
from src.data.LoadTPLTGT import load_tgt, load_tpl
from src.data.LoadDisPotential import Load_EdgeScore
from src.data.LoadHHM import load_hhm
from src.data.DataProcessor import readDataList, get_tpl_type, get_tgt_type, \
    get_dist_type
from src.data.DataSet import PairwiseDataSet, NDTAlignmentDataSet
from src.model.ObsModel import ObsModel, ADMMModel
from src.model.BatchPair import Batchpair
from src.model.Utils import alignment_output
from src.model import Crf4SeqAlign as CrfModel
from src.model.Configure import ModelConfigure, ADMMConfigure

torch.multiprocessing.set_sharing_strategy("file_system")
torch.set_printoptions(edgeitems=100)

example_text = "example:\n  OMP_NUM_THREADS=1 python3 BatchRNDTAlign.py " \
    "-m params/RNDTmodel.DA.1.pth -l example/alignment_list " \
    "-t database/TPL_BC100 -q database/TGT_BC100 " \
    "-d database/DIST_BC100 -o output -g 0 -a MaxAcc"
parser = argparse.ArgumentParser(
    description="Predict alignment between a list of query sequence/TGT "
    "and a list of template protein/TPL",
    usage="environment variable: set OMP_NUM_THREADS=1 \n"
    "python3 BatchRNDTAlign.py -l PairList -m [Models] -t TPLs_path "
    "-q TGTs_path -d DISTs_path [-g GPU] [-c CPU_num] "
    "[-a {Viterbi, MaxAcc}] [-o Output_path]",
    epilog=example_text,
    formatter_class=argparse.RawTextHelpFormatter)
parser._action_groups.pop()
required = parser.add_argument_group("required arguments")
optional = parser.add_argument_group("optional arguments")
other = parser.add_argument_group("other arguments")
required.add_argument(
    "-l", required=True,
    help="List of alignment name for test, \n"
    "each line in alignment list is a string with format "
    "queryName-templateName")
required.add_argument(
    "-m", required=True, default=[], nargs="+",
    help="Model path for test, can use more than one model")
required.add_argument(
    "-t", required=True, help="Template proteins/TPLs path")
required.add_argument(
    "-q", required=True, help="Query sequences/TGTs/HHMs path")
required.add_argument(
    "-d", required=True, help="Pairwise feature/distance_potential/epad path")
optional.add_argument(
    "-a", default="MaxAcc", choices=["Viterbi", "MaxAcc"],
    help="Algorithm use to generate alignment from observation matrix,\n"
    " only support Viterbi and MaxAcc, [default = MaxAcc]")
optional.add_argument(
    "-g", type=int, nargs="+", default=[0],
    help="Gpu device you use to run our model [default = 0]")
optional.add_argument(
    "-c", type=int, default=20,
    help="Cpu number you use in your project [default = 20]")
optional.add_argument(
    "-o", default="",
    help="Output path [default = ${alignment_list}_NDTResult]\n"
    "Its output consists of three parts:\n"
    "[1] all pairwise alignments, \n"
    "    save in output_path/alignments\n"
    "[2] rank file for each alignment in such format\n"
    "    1       2      3      4    5    6     7      8     "
    "  9     10      11      12         13      14\n"
    "  q_name  t_name  q_len t_len col  q_gap t_gap  q_start "
    "q_end t_start t_end viterbi_sco  seqid   id/ml\n"
    "    save in output_path/alignment_list.Score\n"
    "[3] score: observation score matrix for each pair, "
    "you can use it directly without loading model\n"
    "    save in output_path/score")
other.add_argument(
    "--A", default="",
    help="init alignment, u can use them directly without"
    " all alignment should end with .fasta")
other.add_argument(
    "--s1", default="",
    help="singleton score path, if already have the singleton score "
    "generated by DRNF for all pair,\nu can use them directly without"
    " loading DRNF model, all file should end with .DRNF.Score.pkl")
other.add_argument(
    "--s2", default="",
    help="alignment score path, if already have the alignment score "
    "generated by NDT for all pair,\nu can use them directly without"
    " loading NDT model, all file should end with .NDT.Score.pkl")
args = parser.parse_args()


# ARGS
GPU = torch.device("cuda:%d" % sorted(args.g)[0] if
                   torch.cuda.is_available() else "cpu")
CPU = torch.device("cpu")
numStates = 3


def generateAlign(tplname, tgtname, observations, transitions):
    tpl = load_tpl(os.path.join(args.t, tplname))
    if args.q.endswith('.hhm') or args.q.endswith('.hhm.pkl'):
        tgt = load_hhm(os.path.join(args.q, tgtname))
    else:
        tgt = load_tgt(os.path.join(args.q, tgtname))
    tgtseq = tgt['sequence']
    tplseq = tpl['sequence']
    model_size = observations.size(0)
    sequence = Batchpair(tpl['name'], tgt['name'], tplseq, tgtseq,
                         tpl, model_size)
    alignments = sequence.alignment_init(observations, transitions, args.a)
    alignments_output = []
    for ba in range(sequence.batchsize):
        alignments_output.append(
            alignment_output(
                tpl['name'], tgt['name'], tpl['sequence'], tgt['sequence'],
                alignments[ba]))
    return [tpl['name'], tgt['name'], alignments_output]


def generateNDTAlign(tplname, tgtname, distname, observations, transitions,
                     init_alignments_path):
    tpl = load_tpl(os.path.join(args.t, tplname))
    if args.q.endswith('.hhm') or args.q.endswith('.hhm.pkl'):
        tgt = load_hhm(os.path.join(args.q, tgtname))
    else:
        tgt = load_tgt(os.path.join(args.q, tgtname))
    tgtseq = tgt['sequence']
    tplseq = tpl['sequence']
    tplname = tpl['name']
    tgtname = tgt['name']
    model_size = observations.size(0)
    sequence = Batchpair(tpl['name'], tgt['name'], tplseq, tgtseq,
                         tpl, model_size)
    dis = tpl['atomDistMatrix']['CbCb']
    dis = torch.from_numpy(dis).float()
    dis = torch.where(torch.lt(dis, 0),
                      torch.ones(dis.size())*10000, dis)
    sequence.set_dismatrix(dis)

    pair_dis, disc_method, _ = Load_EdgeScore(
        os.path.join(args.d, distname), tgt)
    pair_dis = torch.from_numpy(pair_dis)
    disc_method = torch.from_numpy(disc_method)

    alignment_paths = []
    for ba in range(model_size):
        if os.path.exists(
            os.path.join(
                init_alignments_path, '%s-%s.%d.fasta' %
                (tplname, tgtname, ba))):
            alignment_path = os.path.join(
                init_alignments_path, '%s-%s.%d.fasta' %
                (tplname, tgtname, ba))
        else:
            alignment_path = os.path.join(
                init_alignments_path, '%s-%s.fasta' % (tplname, tgtname))
        alignment_paths.append(alignment_path)

    alignments = sequence.alignment_init(observations, transitions, args.a)
    node_score, edge_score, norm_score = sequence.compute_NDT_score(
        alignments, observations, transitions, pair_dis, disc_method)
    sequence.update4NDT(alignments, node_score, edge_score, norm_score)

    alignment = sequence.maxalign

    output = sequence.get_RNDToutput(
        alignment, observations[sequence.bestobs].unsqueeze(0),
        transitions[sequence.bestobs].unsqueeze(0), pair_dis, disc_method,
        'dist', 1)
    alignment_out = sequence.get_alignment_output()

    return [tpl['name'], tgt['name'], output, alignment_out]


if __name__ == "__main__":
    # device
    if not torch.cuda.is_available():
        print("cuda is not avaiable")
        sys.exit(-1)
    # check the obs if it set
    if args.s1 != '' and not os.path.exists(args.s1):
        print("s1 path for singleton score %s is not existing" % (args.s1))
        sys.exit(-1)
    # testlist
    if not os.path.exists(args.l):
        print("input alignment list %s is not existing" % args.l)
        sys.exit(-1)
    # output
    if args.o == "":
        outputname = os.path.basename(args.l) + '_NDTResult'
    else:
        outputname = args.o
    if not os.path.exists(outputname):
        os.makedirs(outputname)
    if args.s1 == '' and args.s2 == '':
        if not os.path.exists(os.path.join(outputname, "DRNFscore")):
            os.makedirs(os.path.join(outputname, "DRNFscore"))
        s1_path = os.path.join(outputname, 'DRNFscore')
    else:
        s1_path = args.s1
    if args.A == '' and args.s2 == '':
        if not os.path.exists(os.path.join(outputname, "Initalign")):
            os.makedirs(os.path.join(outputname, "Initalign"))
        init_path = os.path.join(outputname, 'Initalign')
    else:
        init_path = args.A
        print("read the initial alignment in %s" % init_path)
    if args.s2 == '':
        if not os.path.exists(os.path.join(outputname, "NDTscore")):
            os.makedirs(os.path.join(outputname, "NDTscore"))
        s2_path = os.path.join(outputname, 'NDTscore')
    else:
        s2_path = args.s2
        print("read the alignment score in %s" % s2_path)

    if os.path.exists(os.path.join(outputname, 'alignment_list.Score')):
        os.remove(os.path.join(outputname, 'alignment_list.Score'))
    if os.path.exists(os.path.join(outputname, 'alignments')):
        shutil.rmtree(os.path.join(outputname, 'alignments'))
    os.makedirs(os.path.join(outputname, 'alignments'))

    # MODEL
    obs_group = []
    dist_group = []
    crf_group = []
    SS3FeatureModes = []
    SS8FeatureModes = []
    ACCFeatureModes = []
    for model_name in args.m:
        if not os.path.exists(model_name):
            print("model %s is not existing" % model_name)
            sys.exit(-1)
        model = torch.load(model_name, pickle_module=pickle,
                           map_location=lambda storage, loc: storage)
        modelConf = ModelConfigure(model['DRNFmodel']['configure'])
        SS3FeatureModes.append(modelConf.SS3FeatureMode)
        SS8FeatureModes.append(modelConf.SS8FeatureMode)
        ACCFeatureModes.append(modelConf.ACCFeatureMode)

        print("Load %s.." % os.path.basename(model_name))

        if args.s1 == "":
            model1 = ObsModel(
                GPU, modelConf.feat1d, modelConf.feat2d,
                modelConf.layers1d, modelConf.neurons1d,
                modelConf.layers2d, modelConf.neurons2d, modelConf.dilation,
                modelConf.seqnet, modelConf.embedding, modelConf.pairwisenet,
                modelConf.block, modelConf.activation, modelConf.affine,
                modelConf.track_running_stats)
            obsmodel = torch.nn.DataParallel(model1, device_ids=sorted(args.g))
            obsmodel.module.load_state_dict(model['DRNFmodel']['obsmodel'])
            obsmodel.to(GPU)
            obs_group.append(obsmodel)

        if args.s2 == "":
            NDTConf = ADMMConfigure(model['configure'])
            model2 = ADMMModel(
                GPU, NDTConf.FeatSize, NDTConf.layers2d, NDTConf.neurons2d,
                NDTConf.dilation, NDTConf.pairwisenet, NDTConf.block,
                NDTConf.activation, NDTConf.affine,
                NDTConf.track_running_stats)
            NDTmodel = torch.nn.DataParallel(
                model2, device_ids=sorted(args.g))
            NDTmodel.module.load_state_dict(model['NDTmodel'])
            NDTmodel.to(GPU)
            dist_group.append(NDTmodel)

        crfmodel = CrfModel.CRFLoss(numStates, CPU).to(CPU)
        crfmodel.load_state_dict(model['DRNFmodel']['crfmodel'])
        crf_group.append(crfmodel)

    print("Finish loading %d model" % len(args.m))

    # get the transitions
    transitions = torch.zeros(len(args.m), 5, 5)
    for i in range(0, len(args.m)):
        transitions[i] = crf_group[i].trans + crf_group[i].P
    transitions = transitions.to(CPU)
    transitions.detach_().share_memory_()

    print('List of alignment:               %s' % args.l)
    print('Templates protein are in         %s' % args.t)
    print('Query sequence are in            %s' % args.q)
    print('Output path:                     %s' % outputname)
    # load template list
    pair_name_list = readDataList(args.l)
    datasize = len(pair_name_list)
    tpl_type = get_tpl_type(args.t)
    tgt_type = get_tgt_type(args.q)
    dist_type = get_dist_type(args.d)
    if tgt_type == '.hhm' or tgt_type == ".hhm.pkl":
        if any(SS3FeatureModes) or any(SS8FeatureModes) \
                or any(ACCFeatureModes):
            print("Please use TGT format file as input or use model "
                  "not using structure information")
            sys.exit(-1)

    if args.s1 == '' and args.s2 == '':
        AlignmentSet = PairwiseDataSet(
                pair_name_list, args.t, args.q,
                SS3FeatureModes, SS8FeatureModes, ACCFeatureModes,
                tpl_type, tgt_type)
        data_generator = data.DataLoader(
                AlignmentSet, batch_size=1, shuffle=False,
                num_workers=10, collate_fn=lambda x: x)
        print("Start generating observation score for DRNF")
        start = time.time()
        for number, pair_data in enumerate(tqdm.tqdm(data_generator)):
            featdata, seqX, seqY, maskX, maskY = pair_data[0]
            _, xLen, yLen, _ = featdata[0].size()
            observation = torch.zeros(len(args.m), xLen, yLen, 3)
            with torch.no_grad():
                for j in range(len(args.m)):
                    observation[j] = obs_group[j](
                        featdata[j], seqX, seqY, maskX, maskY
                        )[0].detach().to(CPU)

            if len(pair_name_list[number].split('-')) == 3:
                tgtname, domainID, tplname = pair_name_list[number].split('-')
                tgtname = "%s-%s" % (tgtname, domainID)
            else:
                tgtname, tplname = pair_name_list[number].split('-')

            torch.save(observation, os.path.join(
                       outputname, "DRNFscore", "%s-%s.DRNF.Score.pkl" %
                       (tplname, tgtname)),
                       pickle_module=pickle)
        print("Finish %d observations generation in %.2fs" %
              (datasize, time.time()-start))

    if args.s2 == '' and args.A == '':
        print("start calculating initial alignment..")
        print('algorithm of initialization is   %s' % args.a)
        start = time.time()
        pbar = tqdm.tqdm(total=datasize)
        pool0 = Pool(processes=args.c)

        def getoutput_init(data):
            tplname = data[0]
            tgtname = data[1]
            outalignments = data[2]
            if len(outalignments) == 1:
                with open(os.path.join(
                          init_path, "%s-%s.fasta" % (tplname, tgtname)),
                          'w') as F:
                    F.write(outalignments[0])
            else:
                for ba in range(len(outalignments)):
                    with open(
                        os.path.join(
                            init_path,
                            '%s-%s.%d.fasta' % (tplname, tgtname, ba)),
                            'w') as f:
                        f.write(outalignments[ba])
            pbar.update()
            return

        for i in range(datasize):
            if len(pair_name_list[i].split('-')) == 3:
                tgtname, domainID, tplname = pair_name_list[i].split('-')
                tgtname = "%s-%s" % (tgtname, domainID)
            else:
                tgtname, tplname = pair_name_list[i].split('-')

            observations = torch.load(
                os.path.join(
                    s1_path, "%s-%s.DRNF.Score.pkl" % (tplname, tgtname)),
                pickle_module=pickle)
            observations = observations.float()
            pool0.apply_async(
                generateAlign, args=(
                    tplname + tpl_type, tgtname + tgt_type, observations,
                    transitions), callback=getoutput_init)
        pool0.close()
        pool0.join()
        pbar.close()

        print("finish initial alignment in %.2fs" % (time.time()-start))

    # empty the cache
    if args.s1 == "" and args.s2 == '':
        del observation, featdata, seqX, seqY, maskX, maskY
        del obsmodel, model1
        del data_generator, AlignmentSet
        with torch.cuda.device(GPU):
            torch.cuda.empty_cache()
    del obs_group, crf_group, crfmodel

    if args.s2 == '':
        NDTAlignmentSet = NDTAlignmentDataSet(
            pair_name_list, args.t, args.q, s1_path, args.d,
            init_path, args.a,
            NDTConf.DistFeatureMode, NDTConf.NormFeatureMode,
            NDTConf.AlignFeatureMode,
            tpl_type, tgt_type, '.DRNF.Score.pkl', dist_type)
        NDTdata_generator = data.DataLoader(
            NDTAlignmentSet, batch_size=1, shuffle=False,
            num_workers=20, collate_fn=lambda x: x)
        print("Start generate alignment score for NDT")
        print('Algorithm of initialization is   %s' % args.a)
        start = time.time()

        for number, pair_data in enumerate(tqdm.tqdm(NDTdata_generator)):
            obs_data, dist_data, maskX, maskY = pair_data[0]
            xLen = maskX[0]
            yLen = maskY[0]
            score = torch.zeros(len(args.m), xLen, yLen, 3)
            with torch.no_grad():
                for j in range(len(args.m)):
                    score[j] = dist_group[j](
                        obs_data[j], dist_data[j], maskX, maskY
                        )[0].detach().to(CPU)
                if len(pair_name_list[number].split('-')) == 3:
                    tgtname, domainID, tplname = \
                        pair_name_list[number].split('-')
                    tgtname = "%s-%s" % (tgtname, domainID)
                else:
                    tgtname, tplname = pair_name_list[number].split('-')
                torch.save(score, os.path.join(
                           outputname, "NDTscore", "%s-%s.NDT.Score.pkl" %
                           (tplname, tgtname)),
                           pickle_module=pickle)
        print("Finish %d objective score in %.2fs" %
              (datasize, time.time()-start))

    print("Start generate alignment for NDT using %s" % args.a)
    start = time.time()
    pbar = tqdm.tqdm(total=datasize)
    pool = Pool(processes=args.c)

    def getoutput(data):
        tplname = data[0]
        tgtname = data[1]
        score_output = data[2]
        outalignment = data[3]
        with open(os.path.join(
                  outputname, "alignments", tplname + '-' +
                  tgtname + '.fasta'), 'w') as f:
            f.write(outalignment)
        with open(os.path.join(
                  outputname, "alignment_list.Score"), "a") as F:
            F.write(score_output)
        pbar.update()
        return

    for i in range(datasize):
        if len(pair_name_list[i].split('-')) == 3:
            tgtname, domainID, tplname = pair_name_list[i].split('-')
            tgtname = "%s-%s" % (tgtname, domainID)
        else:
            tgtname, tplname = pair_name_list[i].split('-')
        observations = torch.load(
                os.path.join(s2_path, "%s-%s.NDT.Score.pkl" %
                             (tplname, tgtname)),
                pickle_module=pickle)
        observations = observations.float()

        pool.apply_async(generateNDTAlign,
                         args=(tplname + tpl_type, tgtname + tgt_type,
                               tgtname + dist_type,
                               observations, transitions, init_path),
                         callback=getoutput)
    pool.close()
    pool.join()
    pbar.close()
    print("Finish calculating alignment in %.2fs" % (time.time()-start))
    print("Finish %d alignment generation and save them in %s" %
          (datasize, outputname))
    print("Date:                            %s" %
          (datetime.datetime.now().strftime("%Y-%m-%d %H:%M")))
    print("Command:                         %s" % " ".join(sys.argv))
    print("Alignment_list:                  %s" % os.path.basename(args.l))
    print("Output path:                     %s" % outputname)
