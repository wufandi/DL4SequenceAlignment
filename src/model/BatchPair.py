import torch
import sys
import os
import numpy as np
from . import Crf4SeqAlign as CrfModel
from . import interface as cpp
from .ADMM import update_potential_y, update_potential_z,\
    update_lambda
from .Utils import getStateNum, getIdenticals, alignment_output, \
        getAlignmentStart, getAlignmentEnd, \
        Alignment_Singleton_Score, Alignment_Pairwise_Score, \
        Compute_CbCb_distance_matrix, getGapTransition
sys.path.append("../../")
from src.data.ReadAlignments import ReadAlignments, refactor_alignment \
    # noqa: E402


# to save the imformation of pairwise sequence,
# including template, sequence, feature and alignment
# each Batchpair only has one pair
# but may have more than one feature (generated by different model)
class Batchpair():
    def __init__(self, tplname, tgtname, tplseq, tgtseq,
                 tpldata, model_size=1):
        self.tplname = tplname
        self.tgtname = tgtname
        self.tplseq = tplseq
        self.tgtseq = tgtseq
        self.xLen = len(tplseq)
        self.yLen = len(tgtseq)
        self.tpldata = tpldata
        self.batchsize = model_size
        self.alignments = []
        self.output = ''
        self.admm_iteration = 0
        self.maxscore = 0
        self.nodescore = 0
        self.edgescore = 0
        self.normscore = 0
        self.bestobs = 0
        self.bestiter = 0
        self.identicals = 0
        self.maxalign = CrfModel.ExpandAlignment([], self.xLen, self.yLen)

    # set the alignment for this Batchpair
    def set_alignment(self, alignments):
        assert len(alignments) == self.batchsize, \
            "alignment size should equal to batchsize"
        self.alignments = alignments

    # set the output score to rank all alignment
    def set_output(self, output):
        self.output = output

    # set the distance matrix for computing pairwise score
    def set_dismatrix(self, dis_matrix):
        self.dis_matrix = dis_matrix

    # set the template searchspace for computing pairwise score
    # to speed up ADMM algorithm
    def set_searchspace(self, searchspace):
        self.SearchSpace = searchspace

    # set the ADMM iteration
    # the iteration number should great than or equal to 0
    # If iteration number equal to 0,
    # only use singleton_score to get the alignment
    def set_iter(self, iteration):
        assert iteration >= 0, "ADMM iteration should great than or equal 0"
        self.admm_iteration = iteration

    # check if stop Admm iteration or not
    def StopOrNot(self, alignment_z, alignments, i):
        # if it won't update the alignment, break
        ifstop = [torch.equal(alignment_z[ba], alignments[ba]) for
                  ba in range(self.batchsize)]
        if all(ifstop):
            return True
        if i >= self.bestiter + 2:
            return True
        # for most pair, it will convergence in 4 iteration
        # if main score is lower than 0 after 2 iteration
        # the template is a bad one
        if i >= 2:
            if self.maxscore <= 0:
                return True
        if i >= 4 and self.batchsize > 2:
            if sum(ifstop) >= self.batchsize - 1 and ifstop[self.bestobs]:
                return True
            if i >= 6 and sum(ifstop) >= self.batchsize - 2 and \
                    ifstop[self.bestobs]:
                return True
        return False

    def update4NDT(self, alignments, node_score, edge_score, norm_score):
        for ba in range(self.batchsize):
            update = True
            if self.nodescore >= node_score[ba]:
                update = False
            if update is True:
                self.maxalign = alignments[ba]
                self.nodescore = node_score[ba]
                self.edgescore = edge_score[ba]
                self.normscore = norm_score[ba]
        return

    # update the alignment
    # we update the alignment when
    # 1. first initialize
    # 2. have better score
    #   1' not bad indentical
    #   2' not bad node_score
    # 3. have much better identical
    # This function has a lot of trick, it must have better method
    def update_alignment(self, alignments, node_score, edge_score, norm_score,
                         node_weight, edge_type, iteration):
        alignmentscore = node_score + edge_score + norm_score
        distscore = edge_score + norm_score
        for ba in range(self.batchsize):
            identicals = getIdenticals(alignments[ba], self.tplseq,
                                       self.tgtseq)
            id_diff = max(10, min(self.xLen, self.yLen) // 40)
            update = False
            # 0.first initialize, here mainscore must > 0
            if self.maxscore == 0:
                update = True

            # 1.If edge_type is epad, only consider edge_score and node_score
            if edge_type == "epad":
                if alignmentscore[ba] - norm_score[ba] > \
                        self.maxscore - self.normscore:
                    update = True

            # 2.identicals increase a lot and edge_score and norm_score do not
            # decrease a lot
            if identicals > self.identicals + id_diff and \
                    alignmentscore[ba] > 0 and \
                    alignmentscore[ba] / self.maxscore > 0.8:
                update = True

            # 3.identicals do not decrease a lot and main score increase
            if identicals >= self.identicals - id_diff // 2:
                if distscore[ba] >= self.edgescore + self.normscore:
                    if node_score[ba] >= self.nodescore:
                        update = True
                    else:
                        # main score increase
                        if alignmentscore[ba] >= self.maxscore:
                            # nodescore do not decrease a lot
                            if (self.nodescore - node_score[ba]) \
                                    / node_weight < \
                                    max(40, self.nodescore / 2.5):
                                update = True
                            # edgescore increase a lot
                            if distscore[ba] > 0 and \
                                    (self.edgescore + self.normscore) > 0:
                                if distscore[ba] / (self.edgescore +
                                                    self.normscore) > 1.05:
                                    update = True
                            if self.edgescore + self.normscore < 0:
                                update = True
                else:
                    # main score increase
                    if alignmentscore[ba] >= self.maxscore:
                        update = True
                    # edge_score do not decrease a lot
                    # but nodescore increase a lot
                    if edge_score[ba] > 0 and self.edgescore > 0 and \
                            (edge_score[ba] / self.edgescore > 0.95 or
                             self.edgescore - edge_score[ba] < 100):
                        if (node_score[ba] - self.nodescore) >= \
                                max(40, self.nodescore / 2.5) * node_weight:
                            update = True
            # 4. identicals decrease but main score increase a lot
            elif identicals >= self.identicals - id_diff:
                if alignmentscore[ba] > 0 and self.maxscore > 0:
                    if alignmentscore[ba] / self.maxscore > 1.5:
                        update = True
                if alignmentscore[ba] > 0 and self.maxscore < 0:
                    update = True
            else:
                if alignmentscore[ba] > 0 and self.maxscore < 0:
                    update = True

            # 5. if edge_score <= 0 or norm_score <= 0 it's a bad alignment
            # so we do not update
            if (edge_score[ba] <= 0 or norm_score[ba] <= 0) and \
                    self.maxscore != 0:
                update = False
            # 6 update
            if update is True:
                self.maxalign = alignments[ba]
                self.maxscore = alignmentscore[ba]
                self.nodescore = node_score[ba]
                self.edgescore = edge_score[ba]
                self.normscore = norm_score[ba]
                self.identicals = identicals
                self.bestobs = ba
                self.bestiter = iteration
        return

    # similar to DCNN_CRF, use Viterbi / MaxAcc to initialize the alignment
    def alignment_init(self, observations, transitions, init_type="Viterbi"):
        batchSize, xLen, yLen, numStates = observations.size()
        obs = observations.detach().numpy()
        tra = transitions.detach().numpy()
        maskX = [self.xLen] * batchSize
        if init_type == "Viterbi":
            maxScores, argmaxPos, tracebacks = cpp.viterbi(
                obs, tra, np.array(maskX).astype(np.int))
        elif init_type == "MaxAcc":
            maskY = [self.yLen] * batchSize
            maxScores, argmaxPos, tracebacks = CrfModel.MaxAcc_init(
                    obs, transitions, maskX, maskY, self.tpldata, self.tgtseq)
            self.acc_score = torch.from_numpy(maxScores)
        elif init_type == "Mix":
            maskY = [self.yLen] * batchSize
            maxScores, argmaxPos, tracebacks = CrfModel.MaxAcc_init(
                obs, transitions, maskX, maskY, self.tpldata, self.tgtseq)

        maxScores = torch.from_numpy(maxScores)
        argmaxPos = torch.from_numpy(argmaxPos)
        tracebacks = torch.from_numpy(tracebacks)
        alignments = []

        for score_max, pos_max, traceback, realLenX in zip(
                maxScores, argmaxPos, tracebacks, maskX):
            if score_max <= 0.0:
                alignments.append(
                        CrfModel.ExpandAlignment([], realLenX, yLen))
                continue
            curr_pos = (pos_max[0], pos_max[1], 0)
            pos_list = [curr_pos]
            while traceback[curr_pos] < 3:
                curr_state = curr_pos[2]
                if curr_state == 0:
                    x = curr_pos[0] - 1
                    y = curr_pos[1] - 1
                elif curr_state == 1:
                    x = curr_pos[0] - 1
                    y = curr_pos[1]
                else:
                    x = curr_pos[0]
                    y = curr_pos[1] - 1
                curr_pos = (x, y, traceback[curr_pos])
                pos_list.insert(0, curr_pos)

            alignment = CrfModel.ExpandAlignment(pos_list, realLenX, yLen)
            alignments.append(alignment)

        return alignments

    # use other software like CNF, old DeepThreader result to
    # generate the initilized alignment
    # path_group is a list containing path
    def add_init_alignment(self, path_group):
        for ba in range(len(path_group)):
            if os.path.exists(os.path.join(path_group[ba], "%s-%s.fasta" %
                                           (self.tplname, self.tgtname))):
                alignment = ReadAlignments(
                        [os.path.join(path_group[ba], "%s-%s.fasta" %
                         (self.tplname, self.tgtname))],
                        [[self.tplname, self.tgtname]])
                alignment = refactor_alignment(alignment)
                self.batchsize += 1
                self.alignments.extend(alignment)
        return

    # if we add some initilized alignment from other software, we should also
    # add their observations, however, we can't get real observations,
    # so we use means(observations)
    def add_observation(self, observations):
        batchSize, xLen, yLen, _ = observations.size()
        if self.batchsize > batchSize:
            mean = torch.mean(observations, 0, keepdim=True).expand(
                    self.batchsize-batchSize, xLen, yLen, 3)
            observations = torch.cat([observations, mean])
        return observations

    # the each position in template, when we calculate the pairwise score, we
    # only consider two position where
    # their distance are smaller than disc_method[-1]
    # and when we use it in admm,
    # we need two part, one is larger than x_pos + 6
    #                   the other part is smaller than x_pos - 6
    #   [0, upper)                   [lower, xLen)
    #     <-|           x_pos           |->
    # X X X X X X X X X X x X X X X X X X X X
    # return a list of search space for each position
    def template_search_space(self, disc_method, edge_type="dist"):
        if edge_type == "epad":
            distance_limit = 20
        else:
            distance_limit = disc_method[-1]
        space = [None] * self.xLen
        for x_pos in range(self.xLen):
            upper = max(0, x_pos-5)
            upper_space = torch.where(
                    self.dis_matrix[x_pos][:upper] < distance_limit)[0]
            lower = min(self.xLen, x_pos+6)
            lower_space = torch.where(
                    self.dis_matrix[x_pos][lower:] < distance_limit)[0]
            lower_space += int(lower)
            space[x_pos] = [lower_space, upper_space]
        return space

    # compute the distance matrix for templates in pairwise sequence
    def compute_distance_matrix(self):
        tpl = self.tpldata
        dis_matrix = Compute_CbCb_distance_matrix(tpl)
        dis_matrix = torch.from_numpy(dis_matrix)
        return dis_matrix

    # modify the observations score by set some bad position
    # Note: do not modify by default
    # 1. MultiHIS, 2.Missing in template, 3. 'X' in template and query
    def ModifyObs(self, observations, node_weight=1):
        isMissing = torch.einsum('a,b->ab',
                                 torch.Tensor(self.tpldata['missing']).bool(),
                                 torch.ones(self.yLen).bool())
        obs_filter = isMissing
        obs_filter = obs_filter.unsqueeze(0).unsqueeze(-1).expand(
            self.batchsize, self.xLen, self.yLen, 3)
        penalty = 5 * node_weight
        observations = torch.where(
            obs_filter, observations - penalty, observations)
        return observations

    # use ADMM_algorithm to optimize the objective function
    # the objective function is:
    # singleton_score * Node_Weight  + pairwise_score *  Edge_Weight
    # here, we do not need Edge_Weight, so we set Edge_Norm to 1
    # while singleton_score = sigma theta_{ij}^u * z_{ij}^u
    # pairwise_score = sigma theta_{ijkl}^{uv} * z_{ij}^u * z_{kl}^v
    # we adding the constraint z_ij^u = y_ij^u
    # and add a Lagrange multiplier Lambda to objective function
    # deal with the Lagrangian dual problem
    # Setting Rho to a constant (=0.2) enables
    # algorithm converge within 10 iteration
    def ADMM_algorithm(self, observations, transitions, pair_dis,
                       disc_method, edge_type,
                       Node_Weight=1, Norm_Weight=5, PRINT_OPTION=False):
        batchSize, xLen, yLen, state = observations.size()
        Lambda = torch.zeros(batchSize, xLen, yLen, state)
        alignments = self.alignments
        Rho = 0.2 * Node_Weight

        # 1.first compute alignment score for initilized alignments
        node_score, edge_score, norm_score = self.compute_alignment_score(
                alignments, observations, transitions, pair_dis,
                disc_method, edge_type, Norm_Weight)
        self.update_alignment(alignments, node_score, edge_score, norm_score,
                              Node_Weight, edge_type, 0)
        if PRINT_OPTION:
            self.print_alignments_output(alignments, observations, transitions,
                                         pair_dis, disc_method,
                                         Norm_Weight, edge_type, 0)

        # 2.we use ADMM algorithm to minimize the objective function
        # initialize z by aligning without edge alignment potential
        alignment_z = alignments
        for i in range(self.admm_iteration):
            alignment_y = update_potential_y(
                    alignment_z, 0.5 * observations, 0.5 * transitions,
                    Lambda, self.SearchSpace, pair_dis, self.dis_matrix,
                    disc_method, Rho, edge_type)
            alignment_z = update_potential_z(
                    alignment_y, 0.5 * observations, 0.5 * transitions,
                    Lambda, self.SearchSpace, pair_dis, self.dis_matrix,
                    disc_method, Rho, edge_type)
            Lambda = update_lambda(Lambda, alignment_y, alignment_z, Rho)

            node_score, edge_score, norm_score = self.compute_alignment_score(
                    alignment_z, observations, transitions, pair_dis,
                    disc_method, edge_type, Norm_Weight)
            self.update_alignment(
                    alignment_z, node_score, edge_score, norm_score,
                    Node_Weight, edge_type, i+1)
            if PRINT_OPTION:
                self.print_alignments_output(
                        alignment_z, observations, transitions,
                        pair_dis, disc_method, Norm_Weight, edge_type, i+1)

            if self.StopOrNot(alignment_z, alignments, i+1):
                break
            alignments = alignment_z
            self.alignments = alignments

        # compute the alignment score for result
        real_obs = observations[self.bestobs].unsqueeze(0)
        output = self.get_output(self.maxalign, real_obs,
                                 transitions[self.bestobs], pair_dis,
                                 disc_method, edge_type, Norm_Weight)

        return self.maxalign, output

    # compute the alignment score
    # alignment score = node_score * Node_Weight + edge_score + \
    #         Norm_Weight * norm_edge_score
    def compute_alignment_score(
            self, alignments, observations, transitions, pair_dis,
            disc_method, edge_type, Norm_Weight):
        node_score = Alignment_Singleton_Score(
                alignments, observations, transitions)
        edge_score, norm_score = Alignment_Pairwise_Score(
                alignments, pair_dis, self.dis_matrix, disc_method,
                edge_type, Norm_Weight)
        return node_score, edge_score, norm_score

    def compute_NDT_score(
            self, alignments, observations, transitions,
            pair_dis, disc_method):
        batchsize = len(alignments)
        NDTmatrix = CrfModel.CalcMarginal(observations, transitions)
        NDTscore = torch.zeros(batchsize)

        for ba in range(batchsize):
            alignLen = alignments[ba].size(0)
            for i in range(alignLen):
                x_pos, y_pos, state = alignments[ba][i]
                if state < 3:
                    NDTscore[ba] += NDTmatrix[ba, x_pos, y_pos, state]
        edge_score, norm_score = Alignment_Pairwise_Score(
            alignments, pair_dis, self.dis_matrix, disc_method, 'dist', 1)
        return NDTscore, edge_score, norm_score

    # compute the alignment score for result
    # alignment score = node_weight * node_score + edge_score
    # rank file should include:
    # queryname, subjectname, query_length, subject_length, align_col,
    # query_start, query_end, subject_start, subject_end, alignment_score
    # node_score, edge_score, identical, SeqId
    def get_output(self, alignments, observations, transitions, pair_dis,
                   disc_method, edge_type, Norm_Weight=5, getall=False):
        if getall:
            node_score = Alignment_Singleton_Score(
                    [alignments], observations, transitions)[0]
            edge_scores, norm_scores = Alignment_Pairwise_Score(
                    [alignments], pair_dis, self.dis_matrix, disc_method,
                    edge_type, Norm_Weight)
            edge_score = edge_scores[0]
            norm_score = norm_scores[0]
        else:
            node_score = self.nodescore
            edge_score = self.edgescore
            norm_score = self.normscore
        queryname = self.tgtname
        subjectname = self.tplname
        query_length = len(self.tgtseq)
        subject_length = len(self.tplseq)
        align_col, querygap, subjectgap = getStateNum(alignments)
        query_start, subject_start = getAlignmentStart(alignments)
        query_end, subject_end = getAlignmentEnd(alignments)
        alignment_score = node_score + edge_score + norm_score
        identicals = getIdenticals(alignments, self.tplseq, self.tgtseq)
        SeqId = identicals / min(query_length, subject_length) * 100
        gap_transition = getGapTransition(alignments)
        output = '{:<14s}{:<12s}{:<5d}{:<5d}'\
                 '{:<5d}{:<5d}{:<5d}{:<5d}'\
                 '{:<5d}{:<5d}{:<5d}{:<10.2f}'\
                 '{:<10.2f}{:<10.2f}{:<10.2f}{:<5d}{:<10.2f}{:<5d}\n'.format(
                  queryname, subjectname, query_length,
                  subject_length, align_col, querygap, subjectgap,
                  query_start, query_end, subject_start,
                  subject_end, alignment_score, node_score, edge_score,
                  norm_score, identicals, SeqId, gap_transition)
        return output

    def get_RNDToutput(self, alignments, observations, transitions, pair_dis,
                       disc_method, edge_type, Norm_Weight=5, getall=False):
        maxacc_score = self.nodescore
        edge_score = self.edgescore
        norm_score = self.normscore
        node_score = Alignment_Singleton_Score(
                    [alignments], observations, transitions)[0]
        queryname = self.tgtname
        subjectname = self.tplname
        query_length = len(self.tgtseq)
        subject_length = len(self.tplseq)
        align_col, querygap, subjectgap = getStateNum(alignments)
        query_start, subject_start = getAlignmentStart(alignments)
        query_end, subject_end = getAlignmentEnd(alignments)

        identicals = getIdenticals(alignments, self.tplseq, self.tgtseq)
        alignment_score = edge_score + 10 * identicals + node_score
        SeqId = identicals / min(query_length, subject_length) * 100
        gap_transition = getGapTransition(alignments)
        output = '{:<14s}{:<12s}{:<5d}{:<5d}'\
                 '{:<5d}{:<5d}{:<5d}{:<5d}'\
                 '{:<5d}{:<5d}{:<5d}{:<10.2f}'\
                 '{:<10.2f}{:<10.2f}{:<10.2f}{:<5d}{:<10.2f}{:<5d}\n'.format(
                  queryname, subjectname, query_length,
                  subject_length, align_col, querygap, subjectgap,
                  query_start, query_end, subject_start,
                  subject_end, alignment_score, maxacc_score, edge_score,
                  norm_score, identicals, SeqId, gap_transition)
        return output

    # compute the alignment score for result
    # it's for DRNF result
    # alignment score = node_weight * node_score + edge_score
    # rank file should include:
    # queryname, subjectname, query_length, subject_length, align_col,
    # query_start, query_end, subject_start, subject_end,
    # node_score, identical, SeqId
    def get_CNF_output(self, alignments, score, transitions, method="Viterbi"):
        if method == "Viterbi" or 'Mix':
            node_score = Alignment_Singleton_Score(
                    [alignments], score, transitions)[0]
            node_score = torch.clamp(node_score, min=0)
        # acc_score is for MaxAcc when runing DRNFSearch.py
        elif method == "MaxAcc":
            node_score = self.acc_score[self.bestobs]
        queryname = self.tgtname
        subjectname = self.tplname
        query_length = len(self.tgtseq)
        subject_length = len(self.tplseq)
        align_col, querygap, subjectgap = getStateNum(alignments)
        query_start, subject_start = getAlignmentStart(alignments)
        query_end, subject_end = getAlignmentEnd(alignments)
        alignment_score = node_score
        identicals = getIdenticals(
                alignments, self.tplseq, self.tgtseq)
        SeqId = identicals / min(query_length, subject_length) * 100
        output = '{:<14s}{:<12s}{:<5d}{:<5d}'\
                 '{:<5d}{:<5d}{:<5d}{:<5d}'\
                 '{:<5d}{:<5d}{:<5d}{:<10.2f}'\
                 '{:<5d}{:<10.2f}\n'.format(
                  queryname, subjectname, query_length,
                  subject_length, align_col, querygap, subjectgap,
                  query_start, query_end, subject_start,
                  subject_end, alignment_score, identicals, SeqId)
        return output

    # combine the output for alignment file(.fasta)
    def get_alignment_output(self):
        output = alignment_output(
                self.tplname, self.tgtname,
                self.tplseq, self.tgtseq, self.maxalign)
        return output

    # print the alignment output
    def print_alignments_output(self, alignments, observations, transitions,
                                pair_dis, disc_method, Norm_Weight,
                                edge_type, iteration):
        print("iteration: %d" % iteration)
        for ba in range(self.batchsize):
            real_obs = observations[ba].unsqueeze(0)
            real_trans = transitions[ba].unsqueeze(0)
            output = self.get_output(
                    alignments[ba], real_obs, real_trans, pair_dis,
                    disc_method, edge_type, Norm_Weight, True)
            print(output.strip())
        print("best alignment, model %d in iteration %d" %
              (self.bestobs, self.bestiter))
        return
